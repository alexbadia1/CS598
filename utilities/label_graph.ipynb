{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading iGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph loaded: 132707 vertices, 663861 edges\n"
     ]
    }
   ],
   "source": [
    "# Basic imports\n",
    "import igraph as ig # type: ignore\n",
    "import matplotlib.pyplot as plt # type: ignore\n",
    "import lzma\n",
    "import pickle\n",
    "\n",
    "# Function to load the pickled graph (from graph_helpers.py)\n",
    "def pickle_read(path):\n",
    "    if path.endswith(\"xz\"):\n",
    "        opener = lzma.open\n",
    "    else:\n",
    "        opener = open\n",
    "    with opener(path, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "# Load the attack graph from pickle\n",
    "graph = pickle_read(\"/home/adil/carbanak/parser/attack_graphs/h3_attack.pickle.xz\")\n",
    "print(f\"Graph loaded: {len(graph.vs)} vertices, {len(graph.es)} edges\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering graph by time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph filtered by time from 2024-04-8 00:00:00 +0000 to 2024-05-30 23:59:59 +0000, updated graph: 132707 vertices, 663861 edges\n"
     ]
    }
   ],
   "source": [
    "from dateutil.parser import parse\n",
    "import datetime\n",
    "\n",
    "def convert_to_unix_time(utc_timestamp, for_carbanak=True):\n",
    "    \"\"\"\n",
    "    Converts a UTC timestamp string to Unix time.\n",
    "    \n",
    "    Args:\n",
    "        utc_timestamp (str): The UTC timestamp string.\n",
    "        for_carbanak (bool): If True, returns Unix time in microseconds (for Carbanak).\n",
    "                             If False, returns Unix time in nanoseconds (for others).\n",
    "                             \n",
    "    Returns:\n",
    "        int: Unix time in microseconds or nanoseconds.\n",
    "    \"\"\"\n",
    "    dt_object = parse(utc_timestamp)\n",
    "    \n",
    "    # Convert to Unix timestamp in seconds\n",
    "    unix_timestamp = datetime.datetime.timestamp(dt_object)\n",
    "    \n",
    "    if for_carbanak:\n",
    "        # Return timestamp in microseconds\n",
    "        return int(unix_timestamp * 1000000)\n",
    "    else:\n",
    "        # Return timestamp in nanoseconds\n",
    "        return int(unix_timestamp * 1000000000)\n",
    "\n",
    "def filter_graph_by_time(graph, start_time, end_time):\n",
    "    \"\"\"Filters the graph to include only nodes and edges within the specified time range.\"\"\"\n",
    "    start_unix = convert_to_unix_time(start_time)\n",
    "    end_unix = convert_to_unix_time(end_time)\n",
    "\n",
    "    # Filter vertices and edges by time\n",
    "    subgraph = graph.subgraph_edges(\n",
    "        [e.index for e in graph.es if start_unix <= e['time'] <= end_unix]\n",
    "    )\n",
    "    return subgraph\n",
    "\n",
    "# UTC times (easier to normalize)\n",
    "start_time = \"2024-04-8 00:00:00 +0000\"\n",
    "end_time = \"2024-05-30 23:59:59 +0000\"\n",
    "\n",
    "# filtering \n",
    "graph = filter_graph_by_time(graph, start_time, end_time)\n",
    "print(f\"Graph filtered by time from {start_time} to {end_time}, updated graph: {len(graph.vs)} vertices, {len(graph.es)} edges\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relabling Nodes and Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node and edge relabeling complete.\n"
     ]
    }
   ],
   "source": [
    "# Apply relabeling to the graph\n",
    "from graph_helpers import relabels\n",
    "\n",
    "relabels(graph)\n",
    "print(\"Node and edge relabeling complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Nodes by Keywords\n",
    "\n",
    "Useful to get uuids of nodes for seeding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find nodes by a keyword in the node name\n",
    "def find_nodes_by_keyword(attack_graph, keyword):\n",
    "    matching_nodes = []\n",
    "    for vertex in attack_graph.vs:\n",
    "        if keyword.lower() in vertex['name'].lower():\n",
    "            matching_nodes.append({\n",
    "                'uuid': vertex['uuid'],\n",
    "                'name': vertex['name'],\n",
    "                'type': vertex['type']\n",
    "            })\n",
    "    return matching_nodes\n",
    "\n",
    "# Example usage:\n",
    "keyword = \"141.43.176.203\" # root cause IP \n",
    "matching_nodes = find_nodes_by_keyword(graph, keyword)\n",
    "\n",
    "# Print the matching nodes\n",
    "for node in matching_nodes:\n",
    "    print(f\" Type: {node['type']}, UUID: {[node['uuid']]}, Name: {node['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Min,Max Times, Contaminating graph and Coloring Graph (Labelling Methodology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['type', 'name', 'time', 'uuid', 'min_time', 'max_time']\n"
     ]
    }
   ],
   "source": [
    "# adding min, max time to vertex nodes \n",
    "from graph_helpers import vertex_times\n",
    "\n",
    "vertex_times(graph)\n",
    "\n",
    "print(graph.vs.attributes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph_helpers import contaminate_graph\n",
    "\n",
    "seed_file = \"\" # add seed file here\n",
    "\n",
    "contaminate_graph(graph, seed_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph_helpers import color_graph\n",
    "\n",
    "# label/color the graph based on seed file\n",
    "color_graph(graph, seed_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels\n",
    "for v in range(0,len(graph.vs)):\n",
    "    vertex = graph.vs[v]\n",
    "    if vertex[\"attack_label\"]:\n",
    "        vertex[\"label\"] = \"attack\"\n",
    "    elif vertex[\"contaminate_label\"]:\n",
    "        vertex[\"label\"] = \"contaminated\"\n",
    "    else:\n",
    "        vertex[\"label\"] = \"benign\"\n",
    "\n",
    "c = 0\n",
    "for v in range(0,len(graph.vs)):\n",
    "    vertex = graph.vs[v]\n",
    "    if vertex[\"type\"] == \"process\" and vertex[\"label\"] == \"attack\":\n",
    "        print(\"%s, %s, %s\" % (vertex[\"uuid\"], vertex[\"name\"], vertex[\"label\"]))\n",
    "        c+=1 \n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "for v in range(0,len(graph.vs)):\n",
    "    vertex = graph.vs[v]\n",
    "    if vertex[\"type\"] == \"process\" and vertex[\"label\"] == \"contaminated\":\n",
    "        print(\"%s, %s, %s\" % (vertex[\"uuid\"], vertex[\"name\"], vertex[\"label\"]))\n",
    "        c+=1 \n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization (Pruning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph_helpers import attack_only, declone_processes, prune_edges, merge_vertices, prune_vertices\n",
    "\n",
    "print(\"Filtering attack only igraph\")\n",
    "attack_only(graph)\n",
    "print(f\"Updated graph: {len(graph.vs)} vertices, {len(graph.es)} edges\")\n",
    "print(\"Decloning processes...\")\n",
    "declone_processes(graph)\n",
    "print(f\"Updated graph: {len(graph.vs)} vertices, {len(graph.es)} edges\")\n",
    "print(\"Pruning Edges...\")\n",
    "prune_edges(graph)\n",
    "print(f\"Updated graph: {len(graph.vs)} vertices, {len(graph.es)} edges\")\n",
    "print(\"Merging Vertices...\")\n",
    "merge_vertices(graph)\n",
    "print(f\"Updated graph: {len(graph.vs)} vertices, {len(graph.es)} edges\")\n",
    "print(\"Re-pruning Edges...\")\n",
    "prune_edges(graph)\n",
    "print(f\"Updated graph: {len(graph.vs)} vertices, {len(graph.es)} edges\")\n",
    "print(\"Pruning Vertices...\")\n",
    "prune_vertices(graph) \n",
    "print(f\"Updated graph: {len(graph.vs)} vertices, {len(graph.es)} edges\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_file = \"plots/theia_3.3_success_gatech_profile.pdf\"\n",
    "\n",
    "g = graph\n",
    "\n",
    "print(\"Plotting %s of size V=%d, E=%d...\" %(pdf_file, len(g.vs), len(g.es)))\n",
    "layout = g.layout_davidson_harel()\n",
    "g.vs[\"label\"] = [g.vs[i][\"name\"] for i in range(0,len(g.vs))]\n",
    "g.vs[\"shape\"] = [\"rectangle\" for t in g.vs[\"name\"]]\n",
    "g.vs[\"height\"] = [25 for n in g.vs[\"name\"]]\n",
    "g.vs[\"width\"] = [20 + 10*(len(n)-1) for n in g.vs[\"name\"]]\n",
    "g.es[\"label\"] = [t for t in g.es[\"type\"]]\n",
    "#lamport_timestamps(g)\n",
    "g.es[\"arrow_size\"] = [1.25 for t in g.es[\"type\"]]\n",
    "ig.plot(g, pdf_file, layout=layout, bbox=(2560, 1080), margin=200)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
